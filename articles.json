{"date": "Feb 08 2025", "updates": [{"title": "Understanding Reasoning LLMs", "short": "Boost LLM reasoning!  Learn 4 key methods: inference-time scaling, pure RL, RL+SFT, and distillation.  DeepSeek R1 shines, offering efficiency. Budget-friendly alternatives like Sky-T1 & TinyZero are also explored. #LLM #Reasoning #AI #DeepLearning", "long": "### Reasoning Models: Enhancing LLMs\nThis article explores methods for improving Large Language Models (LLMs) to excel at complex reasoning tasks.\n\n### Defining \"Reasoning Model\"\nReasoning models are LLMs enhanced to handle multi-step problems, unlike simple question-answering.  They often include intermediate steps showing their thought process.\n\n### When to Use Reasoning Models\nReasoning models are best for complex tasks like puzzles and coding; simpler tasks are better handled by standard LLMs.  They are often more expensive and verbose.\n\n### DeepSeek R1 Training Pipeline\nDeepSeek created three R1 models: R1-Zero (pure RL), R1 (RL + SFT), and R1-Distill (smaller models fine-tuned on R1 data). R1-Zero's pure RL approach showed reasoning can emerge without supervised learning.\n\n### Four Main Approaches to Building Reasoning Models\nFour key methods are discussed: inference-time scaling (increasing computational resources during inference), pure RL, RL + SFT, and SFT + distillation (training smaller models on data from larger models).\n\n### DeepSeek R1 and OpenAI's o1\nDeepSeek R1 is comparable to OpenAI's o1 but is more inference-time efficient, suggesting different training approaches.  DeepSeek's open-sourcing under MIT license is highlighted.\n\n### Building Reasoning Models on a Budget\nDistillation helps create effective smaller models at lower costs.  The Sky-T1 model (32B trained for $450) and TinyZero (3B, self-verification, &lt;$30 training cost) are discussed as cost-effective examples.\n\n### Journey Learning\nJourney learning, an advanced SFT method, incorporates both correct and incorrect solution paths, possibly improving model reliability.", "url": "https://magazine.sebastianraschka.com/p/understanding-reasoning-llms"}, {"title": "Noteworthy AI Research Papers of 2024 (Part Two)", "short": "LLM advancements in 2024: Llama 3's improved training, inference-time compute optimization for better accuracy, multimodal LLM paradigms, replicating OpenAI's O1 reasoning, precision scaling laws, & Phi-4's use of synthetic data.  #LLM #AI #research", "long": "### Llama 3:  A significant evolution from Llama 2, featuring enhanced pre-training and post-training pipelines, resulting in a family of models ranging from 8B to 405B parameters.  The paper highlights improvements in training techniques and the shift from RLHF-PPO to DPO for post-training.\n\n### Inference-Time Compute: Scaling inference-time compute is shown to be more effective than solely increasing model parameters for improving LLM outputs on difficult tasks. Techniques like generating multiple solutions and adaptive response revisions are explored.\n\n### Multimodal LLMs:  A comparison of multimodal LLM paradigms (unified embedding decoder and cross-modality attention) is presented, along with a hybrid approach that combines the benefits of both.\n\n### Replicating OpenAI's O1:  Research efforts to replicate OpenAI's O1 model's reasoning capabilities are detailed, focusing on the concept of \\\"journey learning\\\" as opposed to \\\"shortcut learning\\\" and the use of distillation techniques.\n\n### LLM Scaling Laws for Precision:  An update to Chinchilla's scaling laws is provided, incorporating low-precision training and inference for improved computational efficiency, highlighting the potential drawbacks of overtraining in low-precision settings.\n\n### Phi-4 and Synthetic Data: The impressive Phi-4 model, trained largely on synthetic data generated by GPT-4, demonstrates the potential benefits of synthetic data in LLM training, emphasizing the need for a balanced approach.", "url": "https://magazine.sebastianraschka.com/p/ai-research-papers-2024-part-2"}, {"title": "Noteworthy AI Research Papers of 2024 (Part One)", "short": "Top 6 AI research papers of 2024 (Jan-June) are summarized: Mixtral's MoE, DoRA's improved LoRA, efficient continual pretraining, DPO vs PPO for LLM alignment, LoRA's learning/forgetting trade-off, and the massive FineWeb dataset.  #AI #LLM #Research #ArtificialIntelligence #MachineLearning", "long": "### Noteworthy AI Research Papers of 2024 (Part One)\n\nThis article summarizes six influential AI research papers published between January and June 2024, focusing on Large Language Model (LLM) advancements.\n\n### January: Mixtral's Mixture of Experts (MoE)\n\nMixtral 8x7B, an open-weight MoE LLM, demonstrated impressive performance exceeding Llama 2 70B and GPT-3.5.  MoE models efficiently allocate computational resources by using multiple smaller subnetworks instead of one large network.\n\n### February: Weight-decomposed LoRA (DoRA)\n\nDoRA improves upon LoRA (Low-Rank Adaptation), a parameter-efficient LLM fine-tuning method, by decomposing weight matrices for better performance and robustness.\n\n### March: Continual Pretraining of LLMs\n\nThis paper suggests simple yet effective strategies for continually pretraining LLMs, including re-warming/re-decaying learning rates and incorporating a small percentage of original pretraining data to mitigate catastrophic forgetting.\n\n### April: DPO vs. PPO for LLM Alignment\n\nThis study compares Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO) for LLM alignment using Reinforcement Learning with Human Feedback (RLHF). PPO generally outperforms DPO, especially with out-of-distribution data.\n\n### May: LoRA Learns Less, Forgets Less\n\nThis research explores the trade-off between LoRA and full fine-tuning. LoRA learns less new information but forgets less of its existing knowledge, particularly beneficial for distant domains. \n\n### June: FineWeb Dataset\n\nThe FineWeb dataset, containing 15 trillion tokens, is a substantial publicly available resource for training large-scale LLMs, offering a principled approach to data filtering and selection.", "url": "https://magazine.sebastianraschka.com/p/ai-research-papers-2024-part-1"}]}